
A null hypothesis is a type of hypothesis used in statistics that proposes that there is no difference between certain characteristics of a population (or data-generating process).
 
For example, a gambler may be interested in whether a game of chance is fair. If it is fair, then the expected earnings per play is 0 for both players. If the game is not fair, then the expected earnings is positive for one player and negative for the other. To test whether the game is fair, the gambler collects earnings data from many repetitions of the game, calculates the average earnings from these data, then tests the null hypothesis that the expected earnings is not different from zero.
 
If the average earnings from the sample data is sufficiently far from zero, then the gambler will reject the null hypothesis and conclude the alternative hypothesis; namely, that the expected earnings per play is different from zero. If the average earnings from the sample data is close to zero, then the gambler will not reject the null hypothesis, concluding instead that the difference between the average from the data and 0 is explainable by chance alone.
 
The null hypothesis, also known as the conjecture, assumes that any kind of difference between the chosen characteristics that you see in a set of data is due to chance. For example, if the expected earnings for the gambling game is truly equal to 0, then any difference between the average earnings in the data and 0 is due to chance.
 
Statistical hypotheses are tested using a four-step process. The first step is for the analyst to state the two hypotheses so that only one can be right. The next step is to formulate an analysis plan, which outlines how the data will be evaluated. The third step is to carry out the plan and physically analyze the sample data. The fourth and final step is to analyze the results and either reject the null hypothesis, or claim that the observed differences are explainable by chance alone.
 
Analysts look to reject the null hypothesis because doing so is a strong conclusion. This requires strong evidence in the form of an observed difference that is too large to be explained solely by chance. Failing to reject the null hypothesis, that the results are explainable by chance alone, is a weak conclusion because it allows that factors other than chance may be at work, but may not be strong enough to be detectable by the statistical test used.
 Analysts look to reject the null hypothesis to rule out some variable(s) as explaining the phenomena of interest. 
Here is a simple example: A school principal claims that students in her school score an average of 7 out of 10 in exams. The null hypothesis is that the population mean is 7.0. To test this null hypothesis, we record marks of say 30 students (sample) from the entire student population of the school (say 300) and calculate the mean of that sample. We can then compare the (calculated) sample mean to the (hypothesized) population mean of 7.0 and attempt to reject the null hypothesis. (The null hypothesis here, that the population mean is 7.0, cannot be proven using the sample data; it can only be rejected.)
 
Take another example: The annual return of a particular mutual fund is claimed to be 8%. Assume that mutual fund has been in existence for 20 years. The null hypothesis is that the mean return is 8% for the mutual fund. We take a random sample of annual returns of the mutual fund for, say, five years (sample) and calculate the sample mean. We then compare the (calculated) sample mean to the (claimed) population mean (8%) to test the null hypothesis.
 
For the above examples, null hypotheses are:
 
For the purposes of determining whether to reject the null hypothesis, the null hypothesis (abbreviated H0) is assumed, for the sake of argument, to be true. Then the likely range of possible values of the calculated statistic (e.g., average score on 30 students’ tests) is determined under this presumption (e.g., the range of plausible averages might range from 6.2 to 7.8 if the population mean is 7.0). Then, if the sample average is outside of this range, the null hypothesis is rejected. Otherwise, the difference is said to be “explainable by chance alone,” being within the range that is determined by chance alone.
 
An important point to note is that we are testing the null hypothesis because there is an element of doubt about its validity. Whatever information that is against the stated null hypothesis is captured in the Alternative Hypothesis (H1). For the above examples, the alternative hypothesis would be:
 
In other words, the alternative hypothesis is a direct contradiction of the null hypothesis.
 
As an example related to financial markets, assume Alice sees that her investment strategy produces higher average returns than simply buying and holding a stock. The null hypothesis states that there is no difference between the two average returns, and Alice is inclined to believe this until she proves otherwise. Refuting the null hypothesis would require showing statistical significance, which can be found using a variety of tests. The alternative hypothesis would state that the investment strategy has a higher average return than a traditional buy-and-hold strategy.
 
One tool that can be used to determine the statistical significance of the results is p-value. A p-value represents the probability that the observed difference between the two returns could occur solely by chance. A p-value that is less than or equal to 0.05 is often used to indicate whether there is evidence against the null hypothesis. If Alice conducts one of these tests, such as a test using the normal model, and proves that the difference between her returns and the buy-and-hold returns is significant (p-value is less than or equal to 0.05), she can then reject the null hypothesis and conclude the alternative hypothesis.
